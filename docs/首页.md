[English](https://github.com/Terark/terarkdb-tests/blob/master/docs/home.md)

# Terark DB BenchmarkTest

本程序执行各种 DB 的 Benchmark，支持的 DB 包括：

* RocksDB  (RocksDB official version)
* TerarkDB (RocksDB on Terark searchable compression algorithms)
* TerichDB
* Wiredtiger


## 目录结构
```bash
build/Terark_Engine_Test # 编译出来的可执行文件
shell # shell 脚本
src
Schema
```

## 输入文件

- **数据源**: 必须是文本文件，每行一条记录，每条记录有多个字段，字段之间用分隔符分隔，分隔符默认是 '\t' ，分隔符可以在命令行指定
- **Key**: 也是文本文件，每行一个 key，该文件中的内容被放入一个数组，以便随机选取一个 key，来进行随机读相应的 value

测试程序对**数据源**的访问是顺序读，所以，当数据源比较大时，数据源可以是 gzip （或其他压缩形式），通过 shell 替换，可以在命令行将数据实时解压，传送给执行程序，例如:<br/>

```bash
diff <(zcat file1.gz) <(zcat file2.gz)
```
直接 diff file1.gz 和 file2.gz 解压后的内容，不需要先解压到中间文件。<br/>
当使用这个技巧时，zcat 可能会成为瓶颈，因为 gzip 的解压速度可能低于 测试程序 读取输入并插入 DB 的速度；并且，这种实时解压会占用一个 CPU，所以，只有在磁盘空间不足时，再使用这种方法。

## RocksDB 存储格式

* Key: 单个 Key 可以是包含多个字段的组合 Key ，组合 Key 的多个字段之间用记录分隔符分隔。
* Value: 输入数据中，去除掉 Key 以外的所有其它字段，按顺序拼接，并使用记录分隔符分隔。

### 分离 Key Value
我们提供了一个程序([splitkv for linux](http://nark.cc/download/splitkv.exe))来将文本数据库（每行由分隔符分隔成字段）中的 key value 拆分成分别的 key文件 和 value文件（用 cut 或 awk 也可以，但速度太慢）。

分离的 Key 与 Value 在文本文件中的格式与在 RocksDB 中存储的格式完全相同。

```bash
cat  lineitem.tbl    | splitkv.exe -k 0,1,2 -d'|' lineitem.key lineitem.value
# 或者，如果使用了 dbgen.sh 进行了压缩：
zcat lineitem.tbl.gz | splitkv.exe -k 0,1,2 -d'|' lineitem.key lineitem.value
```

分离的 key 可以使用 [nlt\_build](https://github.com/Terark/terark-wiki-zh_cn/blob/master/tools/bin/nlt_build.exe.md) 进行压缩并测试<br/>
分离的 value 可以使用 [zbs\_build](https://github.com/Terark/terark-wiki-zh_cn/blob/master/tools/bin/zbs_build.exe.md) 进行压缩并测试

## 命令行参数

命令行格式： `build/Terark_Engine_Test WhichDB Options`

WhichDB 可以是:
* rocksdb
* terarkdb
* terichdb
* wiredtiger

目前经过充分测试的包括： rocksdb, wiredtiger, terarkdb 。

### 选项参数(Options)

必需有参数的选项名均以 '=' 结尾，例如 `--keyfields='|'`

|选项(Option)|说明|
|------------|---------------|
|--action=|load 或者 run<br/>load 是只写，以最快速度把数据写入 DB 并执行 compact, compact 结束程序就退出<br/>run 可以执行读写混合测试，程序会一直运行，直到用户按下 `Ctrl + C`<br/>verify 执行验证测试，验证完成后程序退出|
|--key\_fields=   |逗号(,)分隔的数字列表，<br/>每个数字表示一个字段序号(字段序号从0开始)|
|--fields\_num=   |每条记录有多少个字段，仅用于数据合法性检查|
|--fields\_delim= |字段分隔符，不指定该参数时，默认'\t'，TPC-H数据的分隔符是'&#124;'，<br/>shell脚本中需要将'&#124;'放入引号中，否则'&#124;' 会被解释为管道|
|--insert\_data\_path=|**数据源**的文件名，可以是 shell 替换，例如 `<(zcat data.gz)`|
|--load\_data\_path=|**数据源**的文件名，可以是 shell 替换，例如 `<(zcat data.gz)`<br/>load 速度比较快，`zcat`的速度可能跟不上.<br/>所以最好使用SSD上存储的未压缩的文件|
|--keys\_data\_path=|预抽取出来的 key 文件，用来进行随机读|
|--cache\_size=|RocksDB/wiredtiger 数据库缓存的尺寸，可以使用 K,M,G,T 后缀。<br/>注意：操作系统的 pagecache 需要另外的内存，如果 cache\_size 设置过大，<br/>可能会导致操作系统 pagecache 太小不够用而引起一些问题|
|--logdir=|用于自定义 RocksDB 的 logdir(记录状态和出错信息)|
|--waldir=|用于自定义 RocksDB 的 waldir(wal 指 Write Ahead Log)|
|--db=|数据库目录，在 RocksDB 中，可以指定多个数据库目录，此时，<br/>参数的格式为: `size1:dir1,size2:dir2,...`，<br/>size表示这个目录可用的空间配额，可以加K,M,G,T后缀，例如100G<br/>rocksdb在多个目录之间的容量平衡分配有问题，有些情况下可能达不到预期效果|
|--alt\_engine\_name=|为这次测试指定一个名字/标签|
|--disable\_wal|禁用 Write Ahead Log, 这会提高写性能，但出错时会丢失数据|
|--flush\_threads=|RocksDB 的 Flush 线程数（将 MemTable 刷新到 SST 文件的线程数），<br/>（Flush 线程的优先级高于 Compact）|
|--num\_levels=|RocksDB 的 Level 数量|
|--write\_buffer\_size=|默认 1G|
|--write\_rate\_limit=|设定写速度，尽量按此速度进行写入，默认 30MB/s<br/>当此参数 **非 0** 时，auto\_slowdown\_write参数**失效**<br/>当此参数 **为 0** 时，auto\_slowdown\_write参数**生效**|
|--target\_file\_size\_multiplier=|层数每增加一层，单个 SST 文件的尺寸增加到这么多倍|
|--enable\_auto\_compact=|1 或 0，1 表示启用自动 compact，0 表示禁用自动 compact，默认为 1|
|--rocksdb\_memtable=|如果指定该参数，必须是 vector（使用 VectorRepFactory）<br/>不指定的话，使用 rocksdb 的默认 memtable<br/> vector memtable 仅在 --action=load 时有用，性能更好|
|--load\_size=|如果输入文件尺寸过大，指定该参数可以只加载这么多数据就停止写操作<br/>(`--action=run`的时候，停止写操作，读操作仍会继续)|
|--use\_universal\_compaction=|1 或 0 <br/>1 表示使用 univeral compaction <br/>0 表示使用 Level based compaction，默认为 1|
|--auto\_slowdown\_write=|1 或 0，默认 1<br/>为 1 时，可能会因为 compact 太慢，导致写降速，<br/>为 0 时，对写速度不做限制，总是尽最大速度写入<br/>仅当 write\_rate\_limit 参数为 0 时，此参数才生效|
|--index\_nest\_level=|默认 3，最小为 2，对 TPC-H，设为 2 可以提高大约 10% 的读性能<br/>默认 3 是个比较均衡的值，更大的值有助于提高 index 的压缩率，但会降低性能|
|--zip\_work\_mem\_soft\_limit=|默认 16G，值越大，越有利于提高大尺寸 SST 的压缩速度(并发度会提高)|
|--zip\_work\_mem\_hard\_limit=|默认 32G，...|
|--small\_task\_mem=|默认 2G <br/> 内存用量小于该尺寸的压缩任务，会忽略 zip\_work\_mem\_soft\_limit <br/> 直接执行<br/>当所有压缩线程的总内存用量达到 zip\_work\_mem\_hard\_limit 时，仍必须等待|
|--checksum\_level=|默认 1，仅检查 metadata ，<br/>设为 2 会在每条记录上增加一个 4 bytes 的 checksum，<br/>设为 3 时，SST 整体计算并验证 checksum|
|--terarkdb\_sample\_ratio=|默认 0.015，terark全局压缩的采样率|
|--terarkdb\_zip\_min\_level=|默认 0，只有 level 大于等于此值时，才使用 terark SST，<br/>否则使用 rocksdb 自身的 BlockBasedTable|
|--index\_cache\_ratio=|默认 0.002，可以提高精确查找(DB.Get)的性能(0.002可以提高大约10%)，<br/>该值设置得越大，对性能提升的帮助越小<br/>该设置对通过 iterator 进行查找/遍历无任何帮助|
|--thread\_num=|前台线程数（对数据库执行读/写/更新操作的线程），<br/>线程编号从0开始，对应前闭后开区间 [0, n) |
|--plan\_config=|参数格式 `configId:读百分比:写百分比:更新百分比`，<br/>和 `--thread_plan_map` 配合，可以<br/>让不同的线程按预定义的读/写/更新比例执行|
|--thread\_plan\_map=|参数格式 `线程编号范围:configId`，<br/>线程编号范围格式 `min-max`，指闭区间[min,max]，<br/>线程编号范围也可以是单个线程编号<br/>未指定 thread\_plan\_map 时，每个线程的默认 configId 是 0|
|--terarkdb\_tmpdir=|terarkdb 专用的临时目录，测试 terarkdb 时必须指定|
|--mysql\_passwd=|指定监控数据库(MySQL)的密码|
|--verify\_kv\_file=|**数据源**的文件名，执行 verify 操作的数据源，可以是 shell 替换，例如 `<(zcat data.gz)`，含 key 和 value 且经过 shuf 后的数据|
|--use\_shuf\_key|若 --keys\_data\_path= 指向已经 shuf 后的 key 文件，则直接顺序读取，不使用 GetRandomKey|
|--cache\_shards|默认 0，仅在 terarkdb 测试时有效。当其设置为大于 0 时使用 terarkdb 缓存，并可通过 --cache\_size 设置缓存大小|
|--min\_pread\_len|默认 -1，当设置为 0 时总是使用 pread，大于 0 时当 BlobStore avg record len > min\_pread\_len 时使用 pread|

### 命令行样例

`shell` 目录中有一些脚本，是命令行使用的标准样例，例如 [Terarkdb\_Tpch\_Run.sh](shell/Terarkdb\_Tpch\_Run.sh)


### 环境变量
有一些全局参数是通过环境变量控制的：

<table><tbody>
<tr><th>环境变量名</th><th>说明</th></tr>
<tr>
 <td>DictZipBlobStore_zipThreads</td>
 <td>该变量未设置时(默认)，相当于 8<br/>
如果机器的 CPU 数量小于 8 ，就是实际的 CPU 数量；<br/>
如果设为 0，表示不使用多线程压缩；</br>
非0时，总是使用多线程压缩，读、压缩、写线程是分离的，<br/>
默认值可以工作的不错，如果需要，可以进行精细控制，<br/>
对于TPC-H数据，8个线程的压缩速度可以达到200MB/s
 </td>
</tr>
<tr>
 <td>MYSQL_SERVER</td>
 <td>该变量未设置时(默认)，使用 Terark 的 Mysql Server </td>
</tr>
<tr>
 <td>MYSQL_PORT</td>
 <td>该变量未设置时(默认)，使用 Mysql 默认的端口 3306 </td>
</tr>
<tr>
 <td>MYSQL_USER</td>
 <td>该变量未设置时(默认)，使用 Terark 默认的 user</td>
</tr>
<tr>
 <td>MONITOR_STAT_FILE_PREFIX</td>
 <td>将系统资源监控数据写入文本文件，有多个文件，该变量指定这些文件名的前缀
  <br/>这些文本文件都是CSV格式（逗号分隔字段）
  <table><tbody>
  <tr>
   <td>${prefix}-ops.txt</td>
   <td>db 操作监控（读、写、更新数量），数据格式：<br/>
   time, op_num, op_type<br/>
   op_type: 0 表示读，1 表示写，2 表示更新  
   </td>
  </tr>
  <tr>
   <td>${prefix}-cpu.txt</td>
   <td>cpu 监控，数据格式：  time, cpu%, iowait</td>
  </tr>
  <tr>
   <td>${prefix}-memory.txt</td>
   <td>内存 监控，数据格式（单位是KB）：<br/>
    time, total, free, cached, resident
   </td>
  </tr>
  <tr>
   <td>${prefix}-dbsize.txt</td>
   <td>db尺寸，数据格式： time, dbsizeKB</td>
  </tr>
  <tr>
   <td>${prefix}-diskinfo.txt</td>
   <td>db尺寸详细信息，数据格式： time, description<br/>
   description 详细描述每个 db 目录的尺寸
   </td>
  </tr>
  </tbody></table>
 </td>
</tbody></table>


## TPC-H 测试数据
我们对 TPC-H 的 dbgen 做了一些修改，改变文本字段的长度，用来生成我们需要的数据。

TPC-H 的多个表中， lineitem 表尺寸最大，所以我们使用 lineitem 表的数据进行测试。**注意**: TPC-H dbgen 生成的数据库文本文件，记录的分隔符是 '|' 。

TPC-H lineitem 表有个字段 comment，是文本类型，该字段贡献了大部分压缩率，dbgen 中该字段的尺寸是硬编码为 27 个字节。为了符合测试要求，我们允许通过环境变量修改该字段的长度；另外增加了一个新的脚本 dbgen.sh 用于直接压缩生成的数据库表，请参考: [github链接](https://github.com/rockeet/tpch-dbgen)

## 预先生成随机采样的 Query Key
通过分离 key value，我们可以得到所有的 key，为了测试随机读性能，我们需要把所有的 Key 都放入内存，并且支持在常数时间内随机取一个 Key，要实现这个需求，最简单的做法是使用 std::vector&lt;std::string&gt;，但这样消耗的内存太多，我们使用了一种简单的优化存储 [fstrvec](https://github.com/Terark/terichdb/tree/master/terark-base/src/terark/util/fstrvec.hpp)，然而，但即使这样，把全部的 Key 保存在内存中，在很多情况下也不太现实(TPC-H 短数据lineitem.comment=512字节时，550GB 数据中 Key 占 22GB)。

所以，我们只在内存中存储一部分 Key，为了达到“随机”读的效果，这些 Key 必须是随机选取的，可以使用 `awk` 脚本，来完成这个随机选取的功能：
```awk
awk '{if(rand()<0.07)print($0)}' # 随机选取 7% 的 key
```

得到的这个采样 key 文件(sampled.keys.txt)之后，将参数 `--keys_data=sampled.keys.txt` 传给测试程序

